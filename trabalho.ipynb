{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from networkx.algorithms.community import girvan_newman,  greedy_modularity_communities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['preprocessed','Keyword Degree', 'Keyword Pagerank', 'Keyword Betweenness', 'Keyword Closeness', 'Keyword Eigenvector']\n",
    "df = pd.read_csv('dataset_tweets_consolidated.csv')\n",
    "for c in cols: df[c] = df[c].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "sa = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_vader(x: str):\n",
    "    \"\"\"A ideia do Vader é passar a frase inteira, incluindo emoticon e pontuação.\"\"\"\n",
    "    text = SentimentIntensityAnalyzer().polarity_scores(x)\n",
    "    return text['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_textblob(x: str):\n",
    "    \"\"\"A ideia do TextBlob é analisar uma sentença inteira. Analisando as diferenças,\n",
    "    são mínimas entre o texto com pontuação e sem pontuação. O seu intervalo é equivalente\n",
    "    ao do Vader, variando de [-1,1].\"\"\"\n",
    "    sentiment = SentimentIntensityAnalyzer()\n",
    "    return TextBlob(x).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa['Vader Text'] = df['text'].apply(lambda x: sentiment_vader(x))\n",
    "sa['TextBlob Text'] = df['text'].apply(lambda x: sentiment_textblob(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols:\n",
    "    sa['TextBlob '+c] = df[c].apply(lambda x: sentiment_textblob(\" \".join(x)))\n",
    "    sa['Vader '+c] = df[c].apply(lambda x: sentiment_vader(\" \".join(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.to_csv('dataset_tweets_vader_textblob.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidated = pd.read_csv('dataset_tweets_consolidated.csv')\n",
    "df_vader_textblob = pd.read_csv('dataset_tweets_vader_textblob.csv')\n",
    "df_rnn = pd.read_csv('dataset_tweets_rnn.csv')\n",
    "df_transformer = pd.read_csv('dataset_tweets_transformer.csv')\n",
    "df_cnn = pd.read_csv('dataset_tweets_cnn.csv')\n",
    "df_nbag = pd.read_csv('dataset_tweets_nbag.csv')\n",
    "df = pd.concat([df_consolidated,df_vader_textblob,df_rnn,df_transformer,df_cnn,df_nbag], axis=1, join='outer')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Vader Text','TextBlob Text', 'TextBlob preprocessed', \n",
    "       'Vader preprocessed', 'TextBlob Keyword Degree', 'Vader Keyword Degree',\n",
    "       'TextBlob Keyword Pagerank', 'Vader Keyword Pagerank',\n",
    "       'TextBlob Keyword Betweenness', 'Vader Keyword Betweenness',\n",
    "       'TextBlob Keyword Closeness', 'Vader Keyword Closeness',\n",
    "       'TextBlob Keyword Eigenvector', 'Vader Keyword Eigenvector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_tostring(x):\n",
    "    if x >= 0: return 'positive'\n",
    "    return 'negative'\n",
    "\n",
    "for c in col: df[c] = df[c].apply(lambda x: prediction_tostring(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Vader Text', 'TextBlob Text', 'TextBlob preprocessed', 'Vader preprocessed',\n",
    "       'TextBlob Keyword Degree', 'Vader Keyword Degree',\n",
    "       'TextBlob Keyword Pagerank', 'Vader Keyword Pagerank',\n",
    "       'TextBlob Keyword Betweenness', 'Vader Keyword Betweenness',\n",
    "       'TextBlob Keyword Closeness', 'Vader Keyword Closeness',\n",
    "       'TextBlob Keyword Eigenvector', 'Vader Keyword Eigenvector',\n",
    "       'RNN Prediction', 'Transformer Prediction', 'CNN Prediction',\n",
    "       'Neural Bag of Words Prediction']\n",
    "\n",
    "# Calcular medidas de avaliação\n",
    "acuracia = {'Medidas': [], 'Valores': []}\n",
    "precision = {'Medidas': [], 'Valores': []}\n",
    "recall = {'Medidas': [], 'Valores': []}\n",
    "f1score = {'Medidas': [], 'Valores': []}\n",
    "\n",
    "for c in col:\n",
    "    acuracia['Medidas'].append(c)\n",
    "    acuracia['Valores'].append(accuracy_score(df['target'], df[c]))\n",
    "    precision['Medidas'].append(c)\n",
    "    precision['Valores'].append(precision_score(df['target'], df[c],pos_label='positive'))\n",
    "    recall['Medidas'].append(c)\n",
    "    recall['Valores'].append(recall_score(df['target'], df[c],pos_label='positive'))\n",
    "    f1score['Medidas'].append(c)\n",
    "    f1score['Valores'].append(f1_score(df['target'], df[c], pos_label='positive'))\n",
    "    \n",
    "metrics = {\n",
    "    'Acurácia': acuracia,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metrics:\n",
    "    # Definir o número de cores desejado (ajuste se necessário)\n",
    "    num_cores = len(metrics[m]['Medidas'])  \n",
    "    \n",
    "    # Escolher o mapa de cores\n",
    "    cmap = plt.colormaps['tab20']  # Escolha o mapa de cores desejado\n",
    "    \n",
    "    # Obter as cores do mapa de cores\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, num_cores)]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x='Medidas', y='Valores', data=metrics[m], palette=colors, hue=metrics[m]['Medidas'])\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate('{:.3f}%'.format(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=8, fontweight='bold', color='black', xytext=(0, 5),\n",
    "                textcoords='offset points')\n",
    "    \n",
    "    # Adicionar título\n",
    "    plt.title(f'Gráfico de Barras Comparando {m}', fontsize=16, fontweight='bold')\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    # Exibir o gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_graphml('./data/grafo_tweets.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nodes: {len(list(graph.nodes))}')\n",
    "print(f'Edges: {len(list(graph.edges))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community = community_louvain.best_partition(graph)\n",
    "\n",
    "louvain = {node: com for node, com in community.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de comunidades: {len(set(louvain.values()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community = girvan_newman(graph)\n",
    "\n",
    "communities = next(community)  \n",
    "\n",
    "girvan_newman = {n: i for i, c in enumerate(communities) for n in c}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de comunidades: {len(set(girvan_newman.values()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community = list(greedy_modularity_communities(graph))\n",
    "\n",
    "greedy_modularity = {n: i for i, c in enumerate(community) for n in c}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de comunidades: {len(set(greedy_modularity.values()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'user': list(graph.nodes),\n",
    "    'louvain': [louvain[x] for x in list(graph.nodes)],\n",
    "    'girvan_newman': [girvan_newman[x] for x in list(graph.nodes)],\n",
    "    'greedy_modularity': [greedy_modularity[x] for x in list(graph.nodes)]\n",
    "}\n",
    "\n",
    "df_community = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidated = pd.read_csv('./data/dataset_tweets_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidated = df_consolidated.drop_duplicates(subset=['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(text):\n",
    "    try:\n",
    "        lista = ast.literal_eval(text)\n",
    "        if isinstance(lista, list):\n",
    "            return lista\n",
    "        else:\n",
    "            return []\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "for kw in ['Keyword Betweenness', 'Keyword Closeness', 'Keyword Eigenvector']:\n",
    "    df_consolidated[kw] = df_consolidated[kw].apply(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloud = pd.merge(df_community, df_consolidated, on=['user'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_target = {\n",
    "    'positive': 1,\n",
    "    'negative': -1\n",
    "}\n",
    "\n",
    "df_cloud['target_num'] = df_cloud['target'].map(map_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_types = ['louvain', 'girvan_newman', 'greedy_modularity']\n",
    "\n",
    "for community_type in communities_types:\n",
    "    for community in sorted(df_cloud[community_type].unique()):\n",
    "        df = df_cloud[df_cloud[community_type] == community].copy()\n",
    "        \n",
    "        df_cloud.loc[df_cloud[community_type] == community, f'{community_type}_mean'] = df['target_num'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloud[df_cloud['louvain_mean'] > 0]['louvain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloud[df_cloud['girvan_newman_mean'] > 0]['girvan_newman'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloud[df_cloud['greedy_modularity_mean'] > 0]['greedy_modularity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud(text):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_user(keyword, user):\n",
    "    communities_types = ['louvain', 'girvan_newman', 'greedy_modularity']\n",
    "    communities_text = []\n",
    "    \n",
    "    user_community = df_cloud[df_cloud['user'] == user]\n",
    "    \n",
    "    for community_type in communities_types:\n",
    "        community = user_community[community_type].iloc[0]\n",
    "        df = df_cloud[df_cloud[community_type] == community].copy()\n",
    "        \n",
    "        text = ' '.join(df[keyword].astype(str))\n",
    "        communities_text.append(text)\n",
    "        \n",
    "        print(f'================================= COMMUNITY ({community_type}) #{community} =================================')\n",
    "        cloud(text)\n",
    "    \n",
    "    print(f'================================= SIMILARITY ({community_type}) =================================')\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(communities_text)\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    for i in range(len(communities_types)):\n",
    "        for j in range(i):\n",
    "            print(f\"{communities_types[i]} vs {communities_types[j]}: {similarity_matrix[i, j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df_cloud.sample(1)['user'].to_numpy()\n",
    "# Mudar para preprocessed\n",
    "\n",
    "for user in users:\n",
    "    print(f'\\n\\n\\n######################################### {user} #########################################\\n')\n",
    "    cloud_user('Keyword Betweenness', user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud_community(keyword, community_type):\n",
    "    for community in sorted(df_cloud[community_type].unique()):\n",
    "        print(f'================================= COMMUNITY ({community_type}) #{community} =================================')\n",
    "        \n",
    "        df = df_cloud[df_cloud[community_type] == community]\n",
    "        \n",
    "        text = ' '.join(df[keyword].astype(str))\n",
    "        \n",
    "        cloud(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cloud_community('Keyword Betweenness', 'greedy_modularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cloud_community('Keyword Betweenness', 'girvan_newman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cloud_community('Keyword Betweenness', 'louvain')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
